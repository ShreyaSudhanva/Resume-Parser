{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidURL",
     "evalue": "URL can't contain control characters. \"/wiki/Samanvitha S\\n\\nsamanvitha.sateesha@gmail.com | (+91) 8904868690\\n\\nOBJECTIVE\\nI am a Computer Science student pursuing\\nmy undergraduate degree and looking\\nforward to utilise my knowledge to be an\\nefﬁcient and valuable resource for the\\norganisation while grooming my skills\\nand expertise for personal growth and\\ndevelopment.\\n\\nEDUCATION\\nJSS SCIENCE AND\\nTECHNOLOGY UNIVERSITY\\nB.E. IN COMPUTER SCIENCE\\n( 2018 - 2022 )\\nMysore, Karnataka\\nCum. GPA: 9.44/10.0 (4 Semesters)\\n\\nJNANODAYA PU COLLEGE\\n2ND PU\\n( 2016 - 2018 )\\nMysuru, Karnataka\\nPercentage: 96%\\n\\nCHRIST PUBLIC SCHOOL\\nCLASS X\\n( 2009 - 2016 )\\nMysuru, Karnataka\\nCum. GPA: 10.0/10.0\\n\\nLINKS\\nGithub:// Samanvitha-Sateesha\\nLinkedIn:// samanvitha-sateesha\\n\\nEXPERIENCE\\nSITEX DIGITECH\\nManagement Intern | June 2020 - November 2020\\n• Managed two projects of the company - Website Revamp and Education App Project.\\nUsed the knowledge of web development by contribute to the project with design ideas.\\n• Was present in the education app project from the root till the fundamental features were\\nsuccessfully implemented. Formed a team of sound and eligible candidates and was involved\\nin brainstorming sessions for the features of the app to weekly reviews and progress\\nanalysis.\\n• Came up with the notion of launching a tic-tac-toe game on Instagram as a shout-out to\\nthe company.\\nPROJECTS\\nYELPCAMP | Node.js, MongoDB, Express.js, HTML, CSS, Bootstrap, JavaScript\\nA dynamic application for campgrounds and features which allows users to create their own\\ncampgrounds, view and comment on others campground etc.\\n\\nSMART LIBRARY APPLICATION | HTML,CSS,JavaScript,Bootstrap, MySQL\\nSmart Library Application has two modules, one each for the user and the admin. Admin can\\nadd, delete and update the information of the books. Users can place an order to borrow the\\nbooks based on its availability.\\n\\nMY RESTFUL BLOG APP | Semantic UI\\nA simple Blog App designed by following the conventions of RESTful routing that consists of\\nall the 7 routes.\\n\\nALGORITHMIC IMPLEMENTATION OF PDA | C++, PDA\\nDesigned a menu driven Push Down Automata to accept various types of Strings in C++\\nCERTIFICATIONS\\nTHE WEB DEVELOPER BOOTCAMP\\n• Udemy | April 2020 | [ Certificate]\\n\\nPYTHON DATA STRUCTURES\\n• Coursera | September 2020 | [ Certificate]\\n\\nSKILLS\\nPROGRAMMING\\n• C • Java • HTML • CSS\\n• Bootstrap • Python\\n• Node.js •Express.js • MongoDB • MySQL\\n\\nPYTHON FOR EVERYBODY\\n• Coursera | September 2020 | [ Certificate]\\nACHIEVEMENTS\\nDSC WEBHOOKS | (2019 - 2020)\\n• One of the winners of the front end web development competition.\\n\\nINSIDESHERPA | JPMORGAN CHASE CO. SOFTWARE ENGINEERING\\nVIRTUAL EXPERIENCE | (May 2020 - July 2020)\\n• Took part in a remote internship, completed the assigned modules and received a\\ncertiﬁcate.\\n\\nTOOLS\\n• Git • LaTeX • GDB\\n\\nAFFILIATIONS\\nINSTITUTION' S INNOVATION\\nCOUNCIL (IIC), JSS STU\\n• Student Coordinator\\n( Jan 2019 - Present )\\n\\n1\" (found at least ' ')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidURL\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-78d85b1877e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mextracted_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhigh_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(extracted_text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mextract_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-3811bfb6e910>\u001b[0m in \u001b[0;36mextract_information\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://en.wikipedia.org/wiki/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#creates soup and opens URL for Google. Begins search with site:wikipedia.com so only wikipedia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#links show up. Uses html parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1368\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1325\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1326\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1280\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0mskips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skip_accept_encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;31m# chunked encoding will happen if HTTP/1.1 is used and either\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mputrequest\u001b[0;34m(self, method, url, skip_host, skip_accept_encoding)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_contains_disallowed_url_pchar_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             raise InvalidURL(f\"URL can't contain control characters. {url!r} \"\n\u001b[0m\u001b[1;32m   1136\u001b[0m                              f\"(found at least {match.group()!r})\")\n\u001b[1;32m   1137\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s %s %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_vsn_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidURL\u001b[0m: URL can't contain control characters. \"/wiki/Samanvitha S\\n\\nsamanvitha.sateesha@gmail.com | (+91) 8904868690\\n\\nOBJECTIVE\\nI am a Computer Science student pursuing\\nmy undergraduate degree and looking\\nforward to utilise my knowledge to be an\\nefﬁcient and valuable resource for the\\norganisation while grooming my skills\\nand expertise for personal growth and\\ndevelopment.\\n\\nEDUCATION\\nJSS SCIENCE AND\\nTECHNOLOGY UNIVERSITY\\nB.E. IN COMPUTER SCIENCE\\n( 2018 - 2022 )\\nMysore, Karnataka\\nCum. GPA: 9.44/10.0 (4 Semesters)\\n\\nJNANODAYA PU COLLEGE\\n2ND PU\\n( 2016 - 2018 )\\nMysuru, Karnataka\\nPercentage: 96%\\n\\nCHRIST PUBLIC SCHOOL\\nCLASS X\\n( 2009 - 2016 )\\nMysuru, Karnataka\\nCum. GPA: 10.0/10.0\\n\\nLINKS\\nGithub:// Samanvitha-Sateesha\\nLinkedIn:// samanvitha-sateesha\\n\\nEXPERIENCE\\nSITEX DIGITECH\\nManagement Intern | June 2020 - November 2020\\n• Managed two projects of the company - Website Revamp and Education App Project.\\nUsed the knowledge of web development by contribute to the project with design ideas.\\n• Was present in the education app project from the root till the fundamental features were\\nsuccessfully implemented. Formed a team of sound and eligible candidates and was involved\\nin brainstorming sessions for the features of the app to weekly reviews and progress\\nanalysis.\\n• Came up with the notion of launching a tic-tac-toe game on Instagram as a shout-out to\\nthe company.\\nPROJECTS\\nYELPCAMP | Node.js, MongoDB, Express.js, HTML, CSS, Bootstrap, JavaScript\\nA dynamic application for campgrounds and features which allows users to create their own\\ncampgrounds, view and comment on others campground etc.\\n\\nSMART LIBRARY APPLICATION | HTML,CSS,JavaScript,Bootstrap, MySQL\\nSmart Library Application has two modules, one each for the user and the admin. Admin can\\nadd, delete and update the information of the books. Users can place an order to borrow the\\nbooks based on its availability.\\n\\nMY RESTFUL BLOG APP | Semantic UI\\nA simple Blog App designed by following the conventions of RESTful routing that consists of\\nall the 7 routes.\\n\\nALGORITHMIC IMPLEMENTATION OF PDA | C++, PDA\\nDesigned a menu driven Push Down Automata to accept various types of Strings in C++\\nCERTIFICATIONS\\nTHE WEB DEVELOPER BOOTCAMP\\n• Udemy | April 2020 | [ Certificate]\\n\\nPYTHON DATA STRUCTURES\\n• Coursera | September 2020 | [ Certificate]\\n\\nSKILLS\\nPROGRAMMING\\n• C • Java • HTML • CSS\\n• Bootstrap • Python\\n• Node.js •Express.js • MongoDB • MySQL\\n\\nPYTHON FOR EVERYBODY\\n• Coursera | September 2020 | [ Certificate]\\nACHIEVEMENTS\\nDSC WEBHOOKS | (2019 - 2020)\\n• One of the winners of the front end web development competition.\\n\\nINSIDESHERPA | JPMORGAN CHASE CO. SOFTWARE ENGINEERING\\nVIRTUAL EXPERIENCE | (May 2020 - July 2020)\\n• Took part in a remote internship, completed the assigned modules and received a\\ncertiﬁcate.\\n\\nTOOLS\\n• Git • LaTeX • GDB\\n\\nAFFILIATIONS\\nINSTITUTION' S INNOVATION\\nCOUNCIL (IIC), JSS STU\\n• Student Coordinator\\n( Jan 2019 - Present )\\n\\n1\" (found at least ' ')"
     ]
    }
   ],
   "source": [
    "\n",
    "from pdfminer import high_level\n",
    "\n",
    "filename = \"Samanvitha_S.pdf\"\n",
    "pages = [0,1] # just the first page\n",
    "\n",
    "extracted_text = high_level.extract_text(filename, \"\", pages)\n",
    "#print(extracted_text)\n",
    "extract_information(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information Extraction Function\n",
    "from bs4 import BeautifulSoup\n",
    "def extract_information(string):\n",
    "    string.replace (\" \", \"+\")\n",
    "    query = string\n",
    "    soup = BeautifulSoup(urllib.request.urlopen(\"https://en.wikipedia.org/wiki/\" + query), \"html.parser\")\n",
    "    #creates soup and opens URL for Google. Begins search with site:wikipedia.com so only wikipedia\n",
    "    #links show up. Uses html parser.\n",
    "    for item in soup.find_all('div', attrs={'id' : \"mw-content-text\"}):\n",
    "        print(item.find('p').get_text())\n",
    "        print('\\n')\n",
    "with open('techatt.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    your_listatt = list(reader)\n",
    "with open('techskill.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    your_list = list(reader)\n",
    "with open('nontechnicalskills.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    your_list1 = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Following are his/her Technical Skills\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Following are his/her Non Technical Skills\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sets are used as it has a a constant time for lookup hence the overall the time for the total code will not exceed O(n)\n",
    "s = set(your_list[0])\n",
    "s1 = your_list\n",
    "s2 = your_listatt\n",
    "skillindex = []\n",
    "skills = []\n",
    "skillsatt = []\n",
    "print('\\n')\n",
    "# print(extract_name(resume_string1))\n",
    "\n",
    "# print('\\n')\n",
    "# print('Phone Number is')\n",
    "# y = extract_phone_numbers(resume_string)\n",
    "# y1 = []\n",
    "# for i in range(len(y)):\n",
    "#     if(len(y[i])>9):\n",
    "#         y1.append(y[i])\n",
    "# print(y1)\n",
    "# print('\\n')\n",
    "# print('Email id is')\n",
    "# print(extract_email_addresses(resume_string))\n",
    "for word in extracted_text.split(\" \"):\n",
    "    if word in s:\n",
    "        skills.append(word)\n",
    "skills1 = list(set(skills))\n",
    "print('\\n')\n",
    "print(\"Following are his/her Technical Skills\")\n",
    "print('\\n')\n",
    "np_a1 = np.array(your_list)\n",
    "for i in range(len(skills1)):\n",
    "    item_index = np.where(np_a1==skills1[i])\n",
    "    skillindex.append(item_index[1][0])\n",
    "\n",
    "nlen = len(skillindex)\n",
    "for i in range(nlen):\n",
    "    print(skills1[i])\n",
    "    print(s2[0][skillindex[i]])\n",
    "    print('\\n')\n",
    "\n",
    "#Sets are used as it has a a constant time for lookup hence the overall the time for the total code will not exceed O(n)\n",
    "s1 = set(your_list1[0])\n",
    "nontechskills = []\n",
    "for word in extracted_text.split(\" \"):\n",
    "    if word in s1:\n",
    "        nontechskills.append(word)\n",
    "nontechskills = set(nontechskills)\n",
    "print('\\n')\n",
    "\n",
    "print(\"Following are his/her Non Technical Skills\")\n",
    "list5 = list(nontechskills)\n",
    "print('\\n')\n",
    "for i in range(len(list5)):\n",
    "    print(list5[i])\n",
    "print('\\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: 'U' mode is deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f5c5ee8d3b56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#for field in line:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samanvitha/.local/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \"\"\"\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     return [\n\u001b[1;32m    132\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samanvitha/.local/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[1;32m    107\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samanvitha/.local/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \"\"\"\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samanvitha/.local/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \"\"\"\n\u001b[0;32m-> 1328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samanvitha/.local/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \"\"\"\n\u001b[0;32m-> 1328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samanvitha/.local/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samanvitha/.local/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \"\"\"\n\u001b[1;32m   1358\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0msl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samanvitha/.local/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samanvitha/.local/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after_tok\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import nltk,csv,numpy \n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "reader = csv.reader(open('techskill.csv', 'rU'), delimiter= \",\",quotechar='|')\n",
    "# tokenData = nltk.word_tokenize(str(reader))\n",
    "for field in reader:\n",
    "    #for field in line:\n",
    "    tokens = word_tokenize(field)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<', '_csv.reader', 'object', 'at', '0x7f972384d898', '>']\n"
     ]
    }
   ],
   "source": [
    "#print(tokenData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('techskill.csv', 'r') as csvfile:  # this will close the file automatically.\n",
    "    reader = csv.reader(csvfile)\n",
    "    for item in a_list:\n",
    "        if item in reader:\n",
    "            print(item)\n",
    "        else:\n",
    "            continue\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Samanvitha', 'S', 'samanvitha.sateesha', '@', 'gmail.com', '|', '(', '+91', ')', '8904868690', 'OBJECTIVE', 'I', 'am', 'a', 'Computer', 'Science', 'student', 'pursuing', 'my', 'undergraduate', 'degree', 'and', 'looking', 'forward', 'to', 'utilise', 'my', 'knowledge', 'to', 'be', 'an', 'efﬁcient', 'and', 'valuable', 'resource', 'for', 'the', 'organisation', 'while', 'grooming', 'my', 'skills', 'and', 'expertise', 'for', 'personal', 'growth', 'and', 'development', '.', 'EDUCATION', 'JSS', 'SCIENCE', 'AND', 'TECHNOLOGY', 'UNIVERSITY', 'B.E', '.', 'IN', 'COMPUTER', 'SCIENCE', '(', '2018', '-', '2022', ')', 'Mysore', ',', 'Karnataka', 'Cum', '.', 'GPA', ':', '9.44/10.0', '(', '4', 'Semesters', ')', 'JNANODAYA', 'PU', 'COLLEGE', '2ND', 'PU', '(', '2016', '-', '2018', ')', 'Mysuru', ',', 'Karnataka', 'Percentage', ':', '96', '%', 'CHRIST', 'PUBLIC', 'SCHOOL', 'CLASS', 'X', '(', '2009', '-', '2016', ')', 'Mysuru', ',', 'Karnataka', 'Cum', '.', 'GPA', ':', '10.0/10.0', 'LINKS', 'Github', ':', '//', 'Samanvitha-Sateesha', 'LinkedIn', ':', '//', 'samanvitha-sateesha', 'EXPERIENCE', 'SITEX', 'DIGITECH', 'Management', 'Intern', '|', 'June', '2020', '-', 'November', '2020', '•', 'Managed', 'two', 'projects', 'of', 'the', 'company', '-', 'Website', 'Revamp', 'and', 'Education', 'App', 'Project', '.', 'Used', 'the', 'knowledge', 'of', 'web', 'development', 'by', 'contribute', 'to', 'the', 'project', 'with', 'design', 'ideas', '.', '•', 'Was', 'present', 'in', 'the', 'education', 'app', 'project', 'from', 'the', 'root', 'till', 'the', 'fundamental', 'features', 'were', 'successfully', 'implemented', '.', 'Formed', 'a', 'team', 'of', 'sound', 'and', 'eligible', 'candidates', 'and', 'was', 'involved', 'in', 'brainstorming', 'sessions', 'for', 'the', 'features', 'of', 'the', 'app', 'to', 'weekly', 'reviews', 'and', 'progress', 'analysis', '.', '•', 'Came', 'up', 'with', 'the', 'notion', 'of', 'launching', 'a', 'tic-tac-toe', 'game', 'on', 'Instagram', 'as', 'a', 'shout-out', 'to', 'the', 'company', '.', 'PROJECTS', 'YELPCAMP', '|', 'Node.js', ',', 'MongoDB', ',', 'Express.js', ',', 'HTML', ',', 'CSS', ',', 'Bootstrap', ',', 'JavaScript', 'A', 'dynamic', 'application', 'for', 'campgrounds', 'and', 'features', 'which', 'allows', 'users', 'to', 'create', 'their', 'own', 'campgrounds', ',', 'view', 'and', 'comment', 'on', 'others', 'campground', 'etc', '.', 'SMART', 'LIBRARY', 'APPLICATION', '|', 'HTML', ',', 'CSS', ',', 'JavaScript', ',', 'Bootstrap', ',', 'MySQL', 'Smart', 'Library', 'Application', 'has', 'two', 'modules', ',', 'one', 'each', 'for', 'the', 'user', 'and', 'the', 'admin', '.', 'Admin', 'can', 'add', ',', 'delete', 'and', 'update', 'the', 'information', 'of', 'the', 'books', '.', 'Users', 'can', 'place', 'an', 'order', 'to', 'borrow', 'the', 'books', 'based', 'on', 'its', 'availability', '.', 'MY', 'RESTFUL', 'BLOG', 'APP', '|', 'Semantic', 'UI', 'A', 'simple', 'Blog', 'App', 'designed', 'by', 'following', 'the', 'conventions', 'of', 'RESTful', 'routing', 'that', 'consists', 'of', 'all', 'the', '7', 'routes', '.', 'ALGORITHMIC', 'IMPLEMENTATION', 'OF', 'PDA', '|', 'C++', ',', 'PDA', 'Designed', 'a', 'menu', 'driven', 'Push', 'Down', 'Automata', 'to', 'accept', 'various', 'types', 'of', 'Strings', 'in', 'C++', 'CERTIFICATIONS', 'THE', 'WEB', 'DEVELOPER', 'BOOTCAMP', '•', 'Udemy', '|', 'April', '2020', '|', '[', 'Certificate', ']', 'PYTHON', 'DATA', 'STRUCTURES', '•', 'Coursera', '|', 'September', '2020', '|', '[', 'Certificate', ']', 'SKILLS', 'PROGRAMMING', '•', 'C', '•', 'Java', '•', 'HTML', '•', 'CSS', '•', 'Bootstrap', '•', 'Python', '•', 'Node.js', '•Express.js', '•', 'MongoDB', '•', 'MySQL', 'PYTHON', 'FOR', 'EVERYBODY', '•', 'Coursera', '|', 'September', '2020', '|', '[', 'Certificate', ']', 'ACHIEVEMENTS', 'DSC', 'WEBHOOKS', '|', '(', '2019', '-', '2020', ')', '•', 'One', 'of', 'the', 'winners', 'of', 'the', 'front', 'end', 'web', 'development', 'competition', '.', 'INSIDESHERPA', '|', 'JPMORGAN', 'CHASE', 'CO.', 'SOFTWARE', 'ENGINEERING', 'VIRTUAL', 'EXPERIENCE', '|', '(', 'May', '2020', '-', 'July', '2020', ')', '•', 'Took', 'part', 'in', 'a', 'remote', 'internship', ',', 'completed', 'the', 'assigned', 'modules', 'and', 'received', 'a', 'certiﬁcate', '.', 'TOOLS', '•', 'Git', '•', 'LaTeX', '•', 'GDB', 'AFFILIATIONS', 'INSTITUTION', \"'\", 'S', 'INNOVATION', 'COUNCIL', '(', 'IIC', ')', ',', 'JSS', 'STU', '•', 'Student', 'Coordinator', '(', 'Jan', '2019', '-', 'Present', ')', '1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/samanvitha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk. download(\"punkt\")\n",
    "#text = \"Think and wonder, wonder and think.\"\n",
    "a_list = nltk. word_tokenize(extracted_text) #Split text into list of words.\n",
    "print(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-84bd21e39a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "for item in a_list:\n",
    "    if item in reader:\n",
    "        print(item)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import nltk\n",
    " nltk.download('stopwords')\n",
    " from nltk.corpus import stopwords\n",
    " #add new words to the list\n",
    " #new_stopwords = [\"individual\", \"title\", \"id\", \"DATE\",\"date\",\"INFO\",\"info\",\"texttext\",\"postinfo\",\"post\",\"reddit\",\"inforeddit\",\"writing\",\"idsubject\",\"text\",\"titletitle\",\"idsubjectid\",\"mtruk\"]\n",
    " stopwrd = nltk.corpus.stopwords.words('english')\n",
    " stopwrd.extend(new_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mysql', 'python', 'python', 'github', 'javascript', 'c++', 'css', 'c']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/samanvitha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def extract():\n",
    "    import csv\n",
    "    skills = []\n",
    "    with open('techskill.csv', newline='') as csvfile:\n",
    "        data = list(csv.reader(csvfile))\n",
    "\n",
    "    #print(data)\n",
    "    nltk. download(\"punkt\")\n",
    "    #text = \"Think and wonder, wonder and think.\"\n",
    "    a_list = nltk. word_tokenize(extracted_text.lower()) #Split text into list of words.\n",
    "    # print(a_list)\n",
    "\n",
    "    for item in data:\n",
    "        for sub_item in item:\n",
    "            if sub_item in a_list:\n",
    "                skills.append(sub_item)\n",
    "    return skills\n",
    "ohho = extract()\n",
    "print(ohho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
